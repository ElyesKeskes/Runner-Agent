behaviors:
  MoveScript:
    trainer_type: ppo
    hyperparameters:
      batch_size: 1024           # Increase for more stable updates
      buffer_size: 10240          # Size of experience replay buffer
      learning_rate: 3.0e-4       # Learning rate for Adam optimizer
      beta: 5.0e-4                # Coefficient for entropy bonus
      epsilon: 0.2                # Epsilon for exploration
      lambd: 0.95                 # Generalized advantage estimation (GAE) lambda
      num_epoch: 5                # Number of epochs for training on each batch
      learning_rate_schedule: constant
      beta_schedule: constant
      epsilon_schedule: linear
    network_settings:
      hidden_units: 256           # Increased for more complex network
      num_layers: 2
      normalize: true              # Normalize observations to improve learning
    reward_signals:
      extrinsic:
        gamma: 0.99               # Discount factor for future rewards
        strength: 1.0              # Strength of extrinsic reward
    max_steps: 5.0e6              # Total number of steps to train
    time_horizon: 64              # Time horizon for experience
    summary_freq: 5000            # Frequency for writing summaries
